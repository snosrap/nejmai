{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "NEJM AI",
  "home_page_url": "https://ai.nejm.org",
  "favicon": "https://ai.nejm.org/favicon.ico",
  "items": [
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIp2500005",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIp2500005",
      "title": "Harnessing Moravec\u2019s Paradox in Health Care: A New Era of Collaborative Intelligence",
      "summary": "This perspective examines the ongoing challenges in integrating artificial intelligence into health care, emphasizing the persistent issues of algorithmic bias, privacy concerns, and the necessity for rigorous validation. It highlights the balance between automation and human oversight, particularly in ethical decision-making and informed consent processes.",
      "content_text": "## Abstract\n\nArtificial intelligence excels at complex data analytics, yet struggles with\nnuanced, sensorimotor tasks that humans perform almost effortlessly \u2014 a\ndichotomy encapsulated by Moravec\u2019s paradox. By strategically harnessing these\ncomplementary strengths, health care can usher in an era of collaborative\nintelligence, optimizing data-intensive workflows, such as clinical trial\nenrollment, and creating more patient-centric models of care.\n\n",
      "date_published": "2025-04-24T00:00:00+00:00",
      "authors": [
        {
          "name": "A. Loaiza-Bonilla and S. Penberthy"
        }
      ],
      "tags": [
        "Perspective"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIp2500005",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/18aa6402-273f-4c7d-9bf0-df8ba7ca2930/aip2500005_f1.gif",
      "content_html": "<h2 property=\"name\">Abstract</h2><div role=\"paragraph\">Artificial intelligence excels at complex data analytics, yet struggles with nuanced, sensorimotor tasks that humans perform almost effortlessly \u2014 a dichotomy encapsulated by Moravec\u2019s paradox. By strategically harnessing these complementary strengths, health care can usher in an era of collaborative intelligence, optimizing data-intensive workflows, such as clinical trial enrollment, and creating more patient-centric models of care.</div>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIp2401122",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIp2401122",
      "title": "Why Is Primary Care Different? Considerations for Machine Learning Development with Electronic Medical Record Data",
      "summary": "This perspective explains how the unique nature of primary care translates to important differences in machine learning model development and adoption for clinical use. Four key considerations are presented to address the use of ML in primary care settings.",
      "content_text": "## Abstract\n\nPrimary care is the foundation of the health care system and a core driver of\npopulation health. Machine learning (ML) has the potential to enhance primary\ncare by improving efficiency, quality, and accessibility, but ML development\nand implementation in primary care remains limited compared with other medical\nspecialties. There are rich opportunities for collaboration and activity in\nthis area. Effective integration requires methods tailored to the unique\ncharacteristics of primary care, including its core functions \u2014 first contact,\ncomprehensiveness, coordination, and continuity \u2014 as well as the distinct\nnature of electronic medical record data. Key considerations include using\nrepresentative primary care data, constructing cohorts that reflect whole-\nperson care, aligning target outcomes with primary care objectives, and\ndeveloping validation strategies suited to decentralized clinical settings.\nAddressing these challenges requires interdisciplinary collaboration and\nincreased investment in primary care-specific ML research. Optimizing ML for\nprimary care could enhance clinical decision-making, improve patient outcomes,\nand drive meaningful innovation in health care.\n\n",
      "date_published": "2025-04-24T00:00:00+00:00",
      "authors": [
        {
          "name": "J.K. Kueper and Others"
        }
      ],
      "tags": [
        "Perspective"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIp2401122",
          "mime_type": "application/pdf"
        }
      ],
      "content_html": "<h2 property=\"name\">Abstract</h2><div role=\"paragraph\">Primary care is the foundation of the health care system and a core driver of population health. Machine learning (ML) has the potential to enhance primary care by improving efficiency, quality, and accessibility, but ML development and implementation in primary care remains limited compared with other medical specialties. There are rich opportunities for collaboration and activity in this area. Effective integration requires methods tailored to the unique characteristics of primary care, including its core functions \u2014 first contact, comprehensiveness, coordination, and continuity \u2014 as well as the distinct nature of electronic medical record data. Key considerations include using representative primary care data, constructing cohorts that reflect whole-person care, aligning target outcomes with primary care objectives, and developing validation strategies suited to decentralized clinical settings. Addressing these challenges requires interdisciplinary collaboration and increased investment in primary care-specific ML research. Optimizing ML for primary care could enhance clinical decision-making, improve patient outcomes, and drive meaningful innovation in health care.</div>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIp2401116",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIp2401116",
      "title": "Challenges in the Postmarket Surveillance of Clinical Prediction Models",
      "summary": "This paper discusses the challenges of postdeployment assessment of predictive artificial intelligence (AI) models in health care, particularly how confounding medical interventions can distort performance evaluation. It explores current limitations in monitoring strategies and suggests advanced causal modeling as a potential solution to ensure that AI models remain effective in dynamic clinical settings.",
      "content_text": "## Abstract\n\nPredictive artificial intelligence (AI) models enhance clinical workflows with\napplications such as prognostication and decision support, yet suffer from\npostdeployment performance challenges due to dataset shifts. Regulatory\nguidelines emphasize the need for continuous monitoring, but actionable\nstrategies are lacking. A significant issue is postdeployment assessment of\npredictive AI models due to confounding medical interventions where effective\ninterventions modify outcomes, introducing bias into performance assessment.\nThis can falsely suggest model decay, leading to unwarranted updates or\ndecommissioning, harming clinical outcomes.\n\nProposed solutions include withholding model outputs, monitoring outcomes as\nsurrogates, or including clinician interventions in models, each with ethical\nor practical limitations. The lack of effective solutions for this problem can\nlead to an abundance of models that cannot be later evaluated, tuned, or\nwithdrawn if they become ineffective, leading to patient harm. Advanced causal\nmodeling to assess counterfactual outcomes may offer a reliable validation\nmethod. Until effective methods for postdeployment monitoring of predictive\nmodels are developed and validated, decisions on model updates should consider\nthe causal pathways and be evidence based, ensuring the sustained utility of\nAI models in dynamic clinical environments.\n\n",
      "date_published": "2025-04-24T00:00:00+00:00",
      "authors": [
        {
          "name": "S. Ansari and Others"
        }
      ],
      "tags": [
        "Perspective"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIp2401116",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/58aef956-e171-4b04-8a14-e4bbc32e8040/aip2401116_f1.gif",
      "content_html": "<h2 property=\"name\">Abstract</h2><div role=\"paragraph\">Predictive artificial intelligence (AI) models enhance clinical workflows with applications such as prognostication and decision support, yet suffer from postdeployment performance challenges due to dataset shifts. Regulatory guidelines emphasize the need for continuous monitoring, but actionable strategies are lacking. A significant issue is postdeployment assessment of predictive AI models due to confounding medical interventions where effective interventions modify outcomes, introducing bias into performance assessment. This can falsely suggest model decay, leading to unwarranted updates or decommissioning, harming clinical outcomes.</div><div role=\"paragraph\">Proposed solutions include withholding model outputs, monitoring outcomes as surrogates, or including clinician interventions in models, each with ethical or practical limitations. The lack of effective solutions for this problem can lead to an abundance of models that cannot be later evaluated, tuned, or withdrawn if they become ineffective, leading to patient harm. Advanced causal modeling to assess counterfactual outcomes may offer a reliable validation method. Until effective methods for postdeployment monitoring of predictive models are developed and validated, decisions on model updates should consider the causal pathways and be evidence based, ensuring the sustained utility of AI models in dynamic clinical environments.</div>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIp2401059",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIp2401059",
      "title": "Regulation of AI: Learnings from Medical Education",
      "summary": "This perspective draws parallels between artificial intelligence (AI) regulation and competency-based medical education (CBME), an existing framework that addresses similar complexities in training human clinicians. The authors propose a CBME framework as a life-cycle approach to regulating AI in health care that offers a dynamic, continuous, and outcomes-based regulatory model to address the unique challenges posed by AI technologies.",
      "content_text": "This perspective draws parallels between artificial intelligence (AI) regulation and competency-based medical education (CBME), an existing framework that addresses similar complexities in training human clinicians. The authors propose a CBME framework as a life-cycle approach to regulating AI in health care that offers a dynamic, continuous, and outcomes-based regulatory model to address the unique challenges posed by AI technologies.",
      "date_published": "2025-04-24T00:00:00+00:00",
      "authors": [
        {
          "name": "K.N. Vokinger, D.R. Soled, and R.-E.E. Abdulnour"
        }
      ],
      "tags": [
        "Perspective"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIp2401059",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/74ec29df-fda9-4363-a666-d53a4539bbdd/aip2401059_f1.gif"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIoa2400703",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIoa2400703",
      "title": "Longitudinal Risk Prediction for Pediatric Glioma with Temporal Deep Learning",
      "summary": "This study describes the development and application of a self-supervised deep-learning approach called temporal learning for analyzing longitudinal medical imaging. It demonstrates that temporal learning improves longitudinal, imaging-based recurrence prediction in pediatric gliomas, and that performance increases incrementally with the number of historical scans available to the algorithm.",
      "content_text": "This study describes the development and application of a self-supervised deep-learning approach called temporal learning for analyzing longitudinal medical imaging. It demonstrates that temporal learning improves longitudinal, imaging-based recurrence prediction in pediatric gliomas, and that performance increases incrementally with the number of historical scans available to the algorithm.",
      "date_published": "2025-04-24T00:00:00+00:00",
      "authors": [
        {
          "name": "D. Tak and Others"
        }
      ],
      "tags": [
        "Original Article"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIoa2400703",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/79a26797-4e7a-4570-8a67-8e26d478314c/aioa2400703_f4.gif"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIoa2400421",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIoa2400421",
      "title": "Calibration of ECG-Based Deep-Learning Algorithm Scores for Patients Flagged as High Risk for Hypertrophic Cardiomyopathy",
      "summary": "This study finds that an out-of-the-box risk classification by a U.S. Food and Drug Administration\u2013cleared artificial intelligence\u2013enabled algorithm for identifying hypertrophic cardiomyopathy from electrocardiograms can have a low predictive value when used for diagnosis in a screened population. Calibrated model scores approximate the probability of disease among those flagged and can both improve the interpretability of model outputs and inform decision-making about subsequent follow-up.",
      "content_text": "This study finds that an out-of-the-box risk classification by a U.S. Food and Drug Administration\u2013cleared artificial intelligence\u2013enabled algorithm for identifying hypertrophic cardiomyopathy from electrocardiograms can have a low predictive value when used for diagnosis in a screened population. Calibrated model scores approximate the probability of disease among those flagged and can both improve the interpretability of model outputs and inform decision-making about subsequent follow-up.",
      "date_published": "2025-04-24T00:00:00+00:00",
      "authors": [
        {
          "name": "J. Lampert and Others"
        }
      ],
      "tags": [
        "Original Article"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIoa2400421",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/pb-assets/ai-site/images/AIoa2400421_Lampert-1745497839993.jpg"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIe2500297",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIe2500297",
      "title": "Model Calibration, Interpretability, and Decision-Making with AI-Based Risk Scores",
      "summary": "Unpacking an important application of model calibration for an out-of-the-box artificial intelligence algorithm used to flag patients who are at high risk for hypertrophic cardiomyopathy, this article explains the use of calibrated scores for patient-level decision-making.",
      "content_text": "Unpacking an important application of model calibration for an out-of-the-box artificial intelligence algorithm used to flag patients who are at high risk for hypertrophic cardiomyopathy, this article explains the use of calibrated scores for patient-level decision-making.",
      "date_published": "2025-04-24T00:00:00+00:00",
      "authors": [
        {
          "name": "J.W. Hogan and V.L. Murthy"
        }
      ],
      "tags": [
        "Editorial"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIe2500297",
          "mime_type": "application/pdf"
        }
      ]
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIcs2401008",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIcs2401008",
      "title": "Clinical Deployment of Real-Time Left Ventricular Ejection Fraction Estimation from Coronary Angiography",
      "summary": "This study evaluates the CathEF deep-learning algorithm, which estimates left ventricular ejection fraction directly from routine left coronary angiograms in acute coronary syndrome patients, eliminating the need for additional contrast or catheterization. The study found that CathEF achieved diagnostic performance comparable to ventriculography, although its accuracy was lower in patients with ST-elevation myocardial infarction or right coronary artery involvement.",
      "content_text": "This study evaluates the CathEF deep-learning algorithm, which estimates left ventricular ejection fraction directly from routine left coronary angiograms in acute coronary syndrome patients, eliminating the need for additional contrast or catheterization. The study found that CathEF achieved diagnostic performance comparable to ventriculography, although its accuracy was lower in patients with ST-elevation myocardial infarction or right coronary artery involvement.",
      "date_published": "2025-04-24T00:00:00+00:00",
      "authors": [
        {
          "name": "P. Th\u00e9riault-Lauzier and Others"
        }
      ],
      "tags": [
        "Case Study"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIcs2401008",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/c97740f9-4b4d-484e-bb17-c57ccf06edf9/aics2401008_f2.gif"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIra2401164",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIra2401164",
      "title": "The Use of Artificial Intelligence for Cancer Therapeutic Decision-Making",
      "summary": "This review examines the evolving role of artificial intelligence (AI) in oncology, particularly in radiology and pathology, and treatment selection using large language models. It highlights key challenges \u2014 such as data quality, model validation, and clinical integration \u2014 and proposes strategies to overcome them to support the effective adoption of AI to improve cancer care and patient outcomes.",
      "content_text": "This review examines the evolving role of artificial intelligence (AI) in oncology, particularly in radiology and pathology, and treatment selection using large language models. It highlights key challenges \u2014 such as data quality, model validation, and clinical integration \u2014 and proposes strategies to overcome them to support the effective adoption of AI to improve cancer care and patient outcomes.",
      "date_published": "2025-04-17T00:00:00+00:00",
      "authors": [
        {
          "name": "O. Elemento, S. Khozin, and C.N. Sternberg"
        }
      ],
      "tags": [
        "Review Article"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIra2401164",
          "mime_type": "application/pdf"
        }
      ]
    }
  ]
}