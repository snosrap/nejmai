{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "NEJM AI",
  "home_page_url": "https://ai.nejm.org",
  "favicon": "https://ai.nejm.org/favicon.ico",
  "items": [
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIp2400727",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIp2400727",
      "title": "Artificial Intelligence\u2013Based Copilots to Generate Causal Evidence",
      "summary": "A structured approach for leveraging advances in generative artificial intelligence to improve the quality of causal analyses using real-world health data.",
      "content_text": "## Abstract\n\nWhile there is growing consensus that real-world data should play a larger\nrole in generating causal evidence for health care, it is less clear whether\nand how AI can help. Current approaches to AI-driven analysis of health data\nare ill-equipped to account for the many threats to causal validity. However,\nthe current human-reliant pipeline for causal analysis also falls short:\nanalyses are complex, require multidisciplinary expertise, and are slow,\nlabor-intensive and error-prone. Here, we speculate how a \u201chuman-in-the-loop\u201d\nAI-based system could help relieve bottlenecks to high-quality causal\nanalyses. We describe how an AI-based causal copilot, leveraging the formal\ninferential structure of the causal road map, could guide and support\nresearchers through a structured process of translating a causal question into\na hypothetical experiment; translating contextual knowledge into transparent\nand well-justified assumptions; designing, testing, and benchmarking a\ncorresponding statistical analysis plan and code (including integration of\nmachine learning on multimodal data); and supporting causal interpretation of\nresults. Such a system could augment the speed and quality with which\nresearchers conduct causal analyses with real-world data, improve transparency\nand verification of analyses and assumptions, and ultimately serve as a basis\nfor point-of-care personalized decision support.\n\n",
      "date_published": "2024-11-22T00:00:00+00:00",
      "authors": [
        {
          "name": "M. Petersen and Others"
        }
      ],
      "tags": [
        "Perspective"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIp2400727",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/d7a6f4dc-901f-4836-a7fd-66da72295164/aip2400727_f1.gif",
      "content_html": "<h2 property=\"name\">Abstract</h2><div role=\"paragraph\">While there is growing consensus that real-world data should play a larger role in generating causal evidence for health care, it is less clear whether and how AI can help. Current approaches to AI-driven analysis of health data are ill-equipped to account for the many threats to causal validity. However, the current human-reliant pipeline for causal analysis also falls short: analyses are complex, require multidisciplinary expertise, and are slow, labor-intensive and error-prone. Here, we speculate how a \u201chuman-in-the-loop\u201d AI-based system could help relieve bottlenecks to high-quality causal analyses. We describe how an AI-based causal copilot, leveraging the formal inferential structure of the causal road map, could guide and support researchers through a structured process of translating a causal question into a hypothetical experiment; translating contextual knowledge into transparent and well-justified assumptions; designing, testing, and benchmarking a corresponding statistical analysis plan and code (including integration of machine learning on multimodal data); and supporting causal interpretation of results. Such a system could augment the speed and quality with which researchers conduct causal analyses with real-world data, improve transparency and verification of analyses and assumptions, and ultimately serve as a basis for point-of-care personalized decision support.</div>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIoa2400659",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIoa2400659",
      "title": "Does AI-Powered Clinical Documentation Enhance Clinician Efficiency? A Longitudinal Study",
      "summary": "Using DAX Copilot did not make clinicians more efficient in EHR use or financial impact, except for time spent in documentation for high DAX users.",
      "content_text": "## Abstract\n\n### Background\n\nNuance\u2019s Dragon Ambient eXperience (DAX) Copilot is an artificial intelligence\n(AI)\u2013driven ambient clinical documentation software platform. Atrium Health, a\nlarge multisite academic learning health system, was the first to use DAX\nCopilot. This study evaluates outcomes for participating clinicians after DAX\nimplementation.\n\n### Methods\n\nIn this longitudinal study, 112 primary care clinicians using DAX were\nrecruited between June and August 2023 along with a control group of 103\nclinicians from similar practices not using DAX. Primary outcomes of\nelectronic health record (EHR) use and financial impact were assessed over 180\ndays using linear mixed models. Within the DAX group were two subgroups:\nactive users (who transferred \u226525% of DAX notes) and high users (who\ntransferred \u226560% of DAX notes). We performed exploratory analyses to compare\nthe control group with DAX subgroups, in addition to subgroup analyses\nstratified by patient volume and clinician specialty.\n\n### Results\n\nAfter controlling for length of intervention, age, gender, provider type,\nyears of practice, and baseline outcome, we did not find statistical\nsignificance in the primary analyses of EHR and financial metrics. Exploratory\nanalyses suggested that small decreases in documentation hours could result\nfrom high DAX usage (means ratio [MR] 0.93, 95% confidence interval [CI] 0.88\nto 0.98) and from implementing DAX with low-volume clinicians (MR 0.91, 95% CI\n0.83 to 0.99) and with family medicine clinicians (MR 0.91, 95% CI 0.85 to\n0.98).\n\n### Conclusions\n\nAI-powered ambient clinical documentation software has been promoted as a\npromising strategy to alleviate the documentation burden faced by outpatient\nclinicians. However, our findings suggest that the tool did not make\nclinicians as a group more efficient. Future studies can further investigate\nthe utility of DAX for clinician subgroups and alternative implementations\nwith improved clinical adoption. (Funded by Wake Forest University Health\nSciences; ClinicalTrials.gov number,\n[NCT06329427](http://clinicaltrials.gov/show/NCT06329427).)\n\n",
      "date_published": "2024-11-22T00:00:00+00:00",
      "authors": [
        {
          "name": "T.-L. Liu and Others"
        }
      ],
      "tags": [
        "Original Article"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIoa2400659",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/63d29d81-c77d-4cb6-9629-af6667e46a59/aioa2400659_f1.gif",
      "content_html": "<h2 property=\"name\">Abstract</h2><section id=\"abs-sec-1\"><h3>Background</h3><div role=\"paragraph\">Nuance\u2019s Dragon Ambient eXperience (DAX) Copilot is an artificial intelligence (AI)\u2013driven ambient clinical documentation software platform. Atrium Health, a large multisite academic learning health system, was the first to use DAX Copilot. This study evaluates outcomes for participating clinicians after DAX implementation.</div></section><section id=\"abs-sec-2\"><h3>Methods</h3><div role=\"paragraph\">In this longitudinal study, 112 primary care clinicians using DAX were recruited between June and August 2023 along with a control group of 103 clinicians from similar practices not using DAX. Primary outcomes of electronic health record (EHR) use and financial impact were assessed over 180 days using linear mixed models. Within the DAX group were two subgroups: active users (who transferred \u226525% of DAX notes) and high users (who transferred \u226560% of DAX notes). We performed exploratory analyses to compare the control group with DAX subgroups, in addition to subgroup analyses stratified by patient volume and clinician specialty.</div></section><section id=\"abs-sec-3\"><h3>Results</h3><div role=\"paragraph\">After controlling for length of intervention, age, gender, provider type, years of practice, and baseline outcome, we did not find statistical significance in the primary analyses of EHR and financial metrics. Exploratory analyses suggested that small decreases in documentation hours could result from high DAX usage (means ratio [MR] 0.93, 95% confidence interval [CI] 0.88 to 0.98) and from implementing DAX with low-volume clinicians (MR 0.91, 95% CI 0.83 to 0.99) and with family medicine clinicians (MR 0.91, 95% CI 0.85 to 0.98).</div></section><section id=\"abs-sec-4\"><h3>Conclusions</h3><div role=\"paragraph\">AI-powered ambient clinical documentation software has been promoted as a promising strategy to alleviate the documentation burden faced by outpatient clinicians. However, our findings suggest that the tool did not make clinicians as a group more efficient. Future studies can further investigate the utility of DAX for clinician subgroups and alternative implementations with improved clinical adoption. (Funded by Wake Forest University Health Sciences; ClinicalTrials.gov number, <a href=\"http://clinicaltrials.gov/show/NCT06329427\" target=\"_blank\">NCT06329427</a>.)</div></section>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIcs2400404",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIcs2400404",
      "title": "National Use of Artificial Intelligence for Eye Screening in Singapore",
      "summary": "Drawing on the experience of the first-ever artificial intelligence software-as-a-medical-device solution successfully approved by regulators and implemented at a country-wide health care system level, this case study discusses a sequential roadmap of lessons learnt in overcoming practical challenges to facilitate the planning of the successful development, adoption, and diffusion of medical AI solutions in health care settings.",
      "content_text": "## Abstract\n\nDiabetes is a major health care challenge, affecting 10% of the global\npopulation. One third of patients with diabetes have an ocular complication\nknown as diabetic retinopathy (DR). DR progression to manifestations such as\nvision-threatening diabetic retinopathy (VTDR) remains the leading cause of\nblindness in working-aged adults. Yearly DR screening is a universally\nrecommended practice in primary care settings for patients with diabetes, but\nit is often difficult to implement due to a lack of staffing and screening\ncapacity in primary care. This case study highlights our experience with\ndeveloping a medical artificial intelligence (AI) software-as-a-medical-device\n(SaMD) solution for DR screening and implementing it at a national level to\nprovide the capacity needed for DR screening in Singapore. Our approach\ninvolved two broad phases. First, we established a national telemedicine\nscreening program, Singapore Integrated Diabetic Retinopathy Program (SiDRP),\nfor population screening of DR in primary care run by trained, nonclinician\nhuman graders. Second, we deployed a deep learning\u2013based AI solution,\nSingapore Eye Lesion Analyzer (SELENA+), into the SiDRP to scale-up the DR\nscreening process by the human graders. We demonstrated the cost-effectiveness\nof this solution, and obtained medical device regulatory approval for clinical\nuse in health care settings. We report the prospective evaluation of SELENA+\nin SiDRP using real-world pilot data from the first 1712 patients\nconsecutively recruited. Sensitivity and specificity of SELENA+ in detection\nof referable DR cases were 94.7% (95% confidence interval [CI] 88.0% to 98.3%)\nand 82.2% (95% CI 80.8% to 83.5%), respectively. In comparison, sensitivity\nand specificity of human graders were 98.9% (95% CI 94.0% to 99.9%) and 97.2%\n(95% CI 96.6\u201397.8%), respectively. For patients with VTDR, SELENA+\ndemonstrated a substantial advantage of higher sensitivity compared with human\nperformance, reflecting the benefit of the fine-tuning of SELENA+ that we\nperformed to enhance the AI solution\u2019s ability to detect VTDR. We outline the\nclinical, technical, operational, regulatory, and governance challenges\nencountered as well as the lessons learnt in this AI algorithm implementation\njourney. We also present a conceptual framework with considerations and\nstrategies for the broader adoption of medical AI SaMD solutions in the field\nof ophthalmology and beyond.\n\n",
      "date_published": "2024-11-19T00:00:00+00:00",
      "authors": [
        {
          "name": "D.V. Gunasekeran and Others"
        }
      ],
      "tags": [
        "Case Study"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIcs2400404",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/131c9304-9298-4d69-bda1-7ec5beb45281/aics2400404_f1.gif",
      "content_html": "<h2 property=\"name\">Abstract</h2><div role=\"paragraph\">Diabetes is a major health care challenge, affecting 10% of the global population. One third of patients with diabetes have an ocular complication known as diabetic retinopathy (DR). DR progression to manifestations such as vision-threatening diabetic retinopathy (VTDR) remains the leading cause of blindness in working-aged adults. Yearly DR screening is a universally recommended practice in primary care settings for patients with diabetes, but it is often difficult to implement due to a lack of staffing and screening capacity in primary care. This case study highlights our experience with developing a medical artificial intelligence (AI) software-as-a-medical-device (SaMD) solution for DR screening and implementing it at a national level to provide the capacity needed for DR screening in Singapore. Our approach involved two broad phases. First, we established a national telemedicine screening program, Singapore Integrated Diabetic Retinopathy Program (SiDRP), for population screening of DR in primary care run by trained, nonclinician human graders. Second, we deployed a deep learning\u2013based AI solution, Singapore Eye Lesion Analyzer (SELENA+), into the SiDRP to scale-up the DR screening process by the human graders. We demonstrated the cost-effectiveness of this solution, and obtained medical device regulatory approval for clinical use in health care settings. We report the prospective evaluation of SELENA+ in SiDRP using real-world pilot data from the first 1712 patients consecutively recruited. Sensitivity and specificity of SELENA+ in detection of referable DR cases were 94.7% (95% confidence interval [CI] 88.0% to 98.3%) and 82.2% (95% CI 80.8% to 83.5%), respectively. In comparison, sensitivity and specificity of human graders were 98.9% (95% CI 94.0% to 99.9%) and 97.2% (95% CI 96.6\u201397.8%), respectively. For patients with VTDR, SELENA+ demonstrated a substantial advantage of higher sensitivity compared with human performance, reflecting the benefit of the fine-tuning of SELENA+ that we performed to enhance the AI solution\u2019s ability to detect VTDR. We outline the clinical, technical, operational, regulatory, and governance challenges encountered as well as the lessons learnt in this AI algorithm implementation journey. We also present a conceptual framework with considerations and strategies for the broader adoption of medical AI SaMD solutions in the field of ophthalmology and beyond.</div>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIp2400567",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIp2400567",
      "title": "Mary Steps Out: Capturing Patient Experience through Qualitative and AI Methods",
      "summary": "An examination of the inherent experiential gap between researchers and their participants by viewing the problem through the lens of a popular thought experiment involving the perception of color.",
      "content_text": "## Abstract\n\nFrank Jackson\u2019s 1982 thought experiment, \u201cMary\u2019s Room,\u201d illustrates the\nphilosophical divide between propositional and experiential knowledge. We\npresent a compelling case for the incorporation of lived experience into\nbiomedical research and advocate the integration of AI \u2014 particularly large\nlanguage models (LLMs) such as GPT-4 \u2014 to bridge this epistemological gap.\nWhen paired with sophisticated natural language processing techniques, LLMs\ncould systematically analyze qualitative data from disconnected electronic\nhealth record data. We explore methodologic use cases \u2014 including grounded\ntheory and thematic analysis \u2014 while addressing the challenges of analytical\nfidelity and bias reduction with continuous human oversight. We suggest that\nAI-augmented qualitative research can uncover hidden insights from a multitude\nof disparate datasets, revealing patient experiences that would otherwise\nremain inaccessible. This integrated approach could enrich the understanding\nof health and disease, while ensuring it is as inclusive and reflective of\nhuman complexity as the lives it seeks to understand and improve.\n\n",
      "date_published": "2024-11-06T00:00:00+00:00",
      "authors": [
        {
          "name": "V. Renard and Others"
        }
      ],
      "tags": [
        "Perspective"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIp2400567",
          "mime_type": "application/pdf"
        }
      ],
      "content_html": "<h2 property=\"name\">Abstract</h2><div role=\"paragraph\">Frank Jackson\u2019s 1982 thought experiment, \u201cMary\u2019s Room,\u201d illustrates the philosophical divide between propositional and experiential knowledge. We present a compelling case for the incorporation of lived experience into biomedical research and advocate the integration of AI \u2014 particularly large language models (LLMs) such as GPT-4 \u2014 to bridge this epistemological gap. When paired with sophisticated natural language processing techniques, LLMs could systematically analyze qualitative data from disconnected electronic health record data. We explore methodologic use cases \u2014 including grounded theory and thematic analysis \u2014 while addressing the challenges of analytical fidelity and bias reduction with continuous human oversight. We suggest that AI-augmented qualitative research can uncover hidden insights from a multitude of disparate datasets, revealing patient experiences that would otherwise remain inaccessible. This integrated approach could enrich the understanding of health and disease, while ensuring it is as inclusive and reflective of human complexity as the lives it seeks to understand and improve.</div>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIcs2400420",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIcs2400420",
      "title": "Large Language Models for More Efficient Reporting of Hospital Quality Measures",
      "summary": "Hospital quality measures are a vital component of a learning health system, yet they remain costly to report, can be statistically underpowered, and suffer from poor interrater reliability. Here, we demonstrate that large language models with interoperable electronic health record data can perform abstractions for complex quality measures that are accurate, consistent, timely, and scalable.",
      "content_text": "## Abstract\n\nHospital quality measures are a vital component of a learning health system,\nyet they can be costly to report, statistically underpowered, and inconsistent\ndue to poor interrater reliability. Large language models (LLMs) have recently\ndemonstrated impressive performance on health care\u2013related tasks and offer a\npromising way to provide accurate abstraction of complete charts at scale. To\nevaluate this approach, we deployed an LLM-based system that ingests Fast\nHealthcare Interoperability Resources data and outputs a completed Severe\nSepsis and Septic Shock Management Bundle (SEP-1) abstraction. We tested the\nsystem on a sample of 100 manual SEP-1 abstractions that University of\nCalifornia San Diego Health reported to the Centers for Medicare & Medicaid\nServices in 2022. The LLM system achieved agreement with manual abstractors on\nthe measure category assignment in 90 of the abstractions (90%; \u03ba=0.82; 95%\nconfidence interval, 0.71 to 0.92). Expert review of the 10 discordant cases\nidentified four that were mistakes introduced by manual abstraction. This\npilot study suggests that LLMs using interoperable electronic health record\ndata may perform accurate abstractions for complex quality measures. (Funded\nby the National Institute of Allergy and Infectious Diseases [1R42AI177108-1]\nand others.)\n\n",
      "date_published": "2024-10-21T00:00:00+00:00",
      "authors": [
        {
          "name": "A. Boussina and Others"
        }
      ],
      "tags": [
        "Case Study"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIcs2400420",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/0b4e3f45-2785-4578-b5f5-491c500bb267/aics2400420_f1.gif",
      "content_html": "<h2 property=\"name\">Abstract</h2><div role=\"paragraph\">Hospital quality measures are a vital component of a learning health system, yet they can be costly to report, statistically underpowered, and inconsistent due to poor interrater reliability. Large language models (LLMs) have recently demonstrated impressive performance on health care\u2013related tasks and offer a promising way to provide accurate abstraction of complete charts at scale. To evaluate this approach, we deployed an LLM-based system that ingests Fast Healthcare Interoperability Resources data and outputs a completed Severe Sepsis and Septic Shock Management Bundle (SEP-1) abstraction. We tested the system on a sample of 100 manual SEP-1 abstractions that University of California San Diego Health reported to the Centers for Medicare &amp; Medicaid Services in 2022. The LLM system achieved agreement with manual abstractors on the measure category assignment in 90 of the abstractions (90%; \u03ba=0.82; 95% confidence interval, 0.71 to 0.92). Expert review of the 10 discordant cases identified four that were mistakes introduced by manual abstraction. This pilot study suggests that LLMs using interoperable electronic health record data may perform accurate abstractions for complex quality measures. (Funded by the National Institute of Allergy and Infectious Diseases [1R42AI177108-1] and others.)</div>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIoa2400865",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIoa2400865",
      "title": "PROTEUS: A Prospective RCT Evaluating Use of AI in Stress Echocardiography",
      "summary": "The first prospective randomized controlled trial for an artificial intelligence device in stress echocardiography examining the impact on patient outcomes.",
      "content_text": "## Abstract\n\n### Background\n\nUse of artificial intelligence (AI) in cardiovascular imaging may potentially\naugment clinical decision-making in disease management, but no prospective\nrandomized controlled trials have assessed the impact on cardiovascular\noutcomes. This study evaluates whether AI\u2013augmented decision-making is non-\ninferior to standard decision-making when selecting participants for invasive\ncoronary angiography following stress echocardiography.\n\n### Methods\n\nPROTEUS was a multicenter, parallel-group randomized controlled trial. We\nenrolled participants undergoing a stress echocardiogram at 20 centers across\nthe United Kingdom between November 2021 and June 2023. Participants were\nrandomly assigned to standard clinical decision-making (control) or decision-\nmaking augmented by AI (intervention). The primary end point was appropriate\nreferral for coronary angiography, with true positives defined as severe\ncoronary disease requiring revascularization in participants referred for\ninvasive angiography and false negatives defined as an acute coronary event\nwithin 6 months. Secondary analysis examined intervention versus control in\nprespecified subgroups where interpretation is known to be more challenging.\n\n### Results\n\nOut of 2341 randomly assigned participants, 2213 (94.53%) completed 6 months\u2019\nfollow-up. Eighty-five participants were referred for angiography, 61 of whom\nhad significant coronary disease. Of the participants not referred, 41\nparticipants had acute coronary syndrome or died within 6 months. The\ndifference between the area under the receiver operating characteristic curve\n(AUROC) for the intervention (0.63; 95% confidence interval (CI), 0.43 to\n0.83) and control (0.55; 95% CI, 0.33 to 0.80), did not meet the prespecified\nnon-inferiority margin of \u22120.05 (difference, 0.09; 95% CI, \u22120.22 to 0. 39).\nThe sensitivity in the intervention (64.2%; 95% CI, 33.3 to 80.0%) and control\n(55.1%; 95% CI, 43.7 to 84.2%) was similar (difference, 9.1%; 95% CI, \u221221.8 to\n39.6%). Likewise, the specificity in the intervention (98.6%; 95% CI, 98.1 to\n99.8%) and control (99.2%; 95% CI, 97.2 to 99.5%) was similar (difference,\n0.6%; 95% CI, \u22122.1 to 0.9%). Subgroup analyses suggest potential benefit of\nAI\u2013augmentation in low-volume stress echocardiography centers.\n\n### Conclusions\n\nAI\u2013augmented decision-making in stress echocardiography did not meet the non-\ninferiority end point when evaluated in a large, prospective randomized\ncontrolled trial, but may be beneficial in low-volume centers. (Funded by the\nAccelerated Access Collaborative and others; ClinicalTrials.gov number,\n[NCT05028179](https://clinicaltrials.gov/study/NCT05028179); ISRCTN number,\n[ISRCTN15113915](https://www.isrctn.com/ISRCTN15113915).)\n\n",
      "date_published": "2024-10-18T00:00:00+00:00",
      "authors": [
        {
          "name": "R. Upton and Others"
        }
      ],
      "tags": [
        "Original Article"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIoa2400865",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/pb-assets/ai-site/images/AIoa2400865_Upton-1729697404220.jpg",
      "content_html": "<h2 property=\"name\">Abstract</h2><section id=\"abs-sec-1\"><h3>Background</h3><div role=\"paragraph\">Use of artificial intelligence (AI) in cardiovascular imaging may potentially augment clinical decision-making in disease management, but no prospective randomized controlled trials have assessed the impact on cardiovascular outcomes. This study evaluates whether AI\u2013augmented decision-making is non-inferior to standard decision-making when selecting participants for invasive coronary angiography following stress echocardiography.</div></section><section id=\"abs-sec-2\"><h3>Methods</h3><div role=\"paragraph\">PROTEUS was a multicenter, parallel-group randomized controlled trial. We enrolled participants undergoing a stress echocardiogram at 20 centers across the United Kingdom between November 2021 and June 2023. Participants were randomly assigned to standard clinical decision-making (control) or decision-making augmented by AI (intervention). The primary end point was appropriate referral for coronary angiography, with true positives defined as severe coronary disease requiring revascularization in participants referred for invasive angiography and false negatives defined as an acute coronary event within 6 months. Secondary analysis examined intervention versus control in prespecified subgroups where interpretation is known to be more challenging.</div></section><section id=\"abs-sec-3\"><h3>Results</h3><div role=\"paragraph\">Out of 2341 randomly assigned participants, 2213 (94.53%) completed 6 months\u2019 follow-up. Eighty-five participants were referred for angiography, 61 of whom had significant coronary disease. Of the participants not referred, 41 participants had acute coronary syndrome or died within 6 months. The difference between the area under the receiver operating characteristic curve (AUROC) for the intervention (0.63; 95% confidence interval (CI), 0.43 to 0.83) and control (0.55; 95% CI, 0.33 to 0.80), did not meet the prespecified non-inferiority margin of \u22120.05 (difference, 0.09; 95% CI, \u22120.22 to 0. 39). The sensitivity in the intervention (64.2%; 95% CI, 33.3 to 80.0%) and control (55.1%; 95% CI, 43.7 to 84.2%) was similar (difference, 9.1%; 95% CI, \u221221.8 to 39.6%). Likewise, the specificity in the intervention (98.6%; 95% CI, 98.1 to 99.8%) and control (99.2%; 95% CI, 97.2 to 99.5%) was similar (difference, 0.6%; 95% CI, \u22122.1 to 0.9%). Subgroup analyses suggest potential benefit of AI\u2013augmentation in low-volume stress echocardiography centers.</div></section><section id=\"abs-sec-4\"><h3>Conclusions</h3><div role=\"paragraph\">AI\u2013augmented decision-making in stress echocardiography did not meet the non-inferiority end point when evaluated in a large, prospective randomized controlled trial, but may be beneficial in low-volume centers. (Funded by the Accelerated Access Collaborative and others; ClinicalTrials.gov number, <a href=\"https://clinicaltrials.gov/study/NCT05028179\" target=\"_blank\">NCT05028179</a>; ISRCTN number, <a href=\"https://www.isrctn.com/ISRCTN15113915\" target=\"_blank\">ISRCTN15113915</a>.)</div></section>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIoa2400468",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIoa2400468",
      "title": "AI-Based Anomaly Detection for Clinical-Grade Histopathological Diagnostics",
      "summary": "A deep anomaly detection approach for histopathology shows high detection performance for a broad range of diseases (including all cancers) within the long diagnostic tail in gastrointestinal biopsies.",
      "content_text": "## Abstract\n\n### Background\n\nWhile previous studies of artificial intelligence (AI) have shown its\npotential for diagnosing diseases using imaging data, clinical implementation\nlags behind. AI models require training with large numbers of examples, which\nare only available for common diseases. In clinical reality, however, the\nmajority of diseases are less frequent, and current AI models overlook or\nmisclassify them. An effective, comprehensive technique is needed for the full\nspectrum of real-world diagnoses.\n\n### Methods\n\nWe collected two large real-world datasets of gastrointestinal (GI) biopsies,\nwhich are prototypical of the problem. Herein, the 10 most common findings\naccounted for approximately 90% of cases, whereas the remaining 10% contained\n56 disease entities, including many cancers. Seventeen million histological\nimages from 5423 cases were used for training and evaluation. We propose a\ndeep anomaly detection (AD) approach that only requires training data from\ncommon diseases to also detect all less frequent diseases.\n\n### Results\n\nWithout specific training for the diseases, our best-performing model reliably\ndetected a broad spectrum of infrequent (\u201canomalous\u201d) pathologies with 95.0%\n(stomach) and 91.0% (colon) area under the receiver operating characteristic\ncurve (AUROC) and was able to generalize between scanners and hospitals.\nCancers were detected with 97.7% (stomach) and 96.9% (colon) AUROC. Heatmaps\nreliably highlighted anomalous areas and can guide pathologists during the\ndiagnostic process.\n\n### Conclusions\n\nIn this study, we establish the first effective clinical application of AI-\nbased AD in histopathology and demonstrate high performance on a unique real-\nworld collection of GI biopsies. The proposed novel AD can flag anomalous\ncases, facilitate case prioritization, and reduce missed diagnoses, providing\ncritical support for pathologists. By design, it can be expected to detect any\npathological alteration including rare primary or metastatic cancers in GI\nbiopsies. To our knowledge, no other published AI tool is capable of zero-shot\npan-cancer detection. AD may enhance the safety of AI models in\nhistopathology, thereby driving AI adoption and automation in routine\ndiagnostics and beyond.\n\n",
      "date_published": "2024-10-18T00:00:00+00:00",
      "authors": [
        {
          "name": "J. Dippel and Others"
        }
      ],
      "tags": [
        "Original Article"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIoa2400468",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/d71cd626-5d9a-43fc-9a63-a7396f3cbc42/aioa2400468_f4.gif",
      "content_html": "<h2 property=\"name\">Abstract</h2><section id=\"abs-sec-1\"><h3>Background</h3><div role=\"paragraph\">While previous studies of artificial intelligence (AI) have shown its potential for diagnosing diseases using imaging data, clinical implementation lags behind. AI models require training with large numbers of examples, which are only available for common diseases. In clinical reality, however, the majority of diseases are less frequent, and current AI models overlook or misclassify them. An effective, comprehensive technique is needed for the full spectrum of real-world diagnoses.</div></section><section id=\"abs-sec-2\"><h3>Methods</h3><div role=\"paragraph\">We collected two large real-world datasets of gastrointestinal (GI) biopsies, which are prototypical of the problem. Herein, the 10 most common findings accounted for approximately 90% of cases, whereas the remaining 10% contained 56 disease entities, including many cancers. Seventeen million histological images from 5423 cases were used for training and evaluation. We propose a deep anomaly detection (AD) approach that only requires training data from common diseases to also detect all less frequent diseases.</div></section><section id=\"abs-sec-3\"><h3>Results</h3><div role=\"paragraph\">Without specific training for the diseases, our best-performing model reliably detected a broad spectrum of infrequent (\u201canomalous\u201d) pathologies with 95.0% (stomach) and 91.0% (colon) area under the receiver operating characteristic curve (AUROC) and was able to generalize between scanners and hospitals. Cancers were detected with 97.7% (stomach) and 96.9% (colon) AUROC. Heatmaps reliably highlighted anomalous areas and can guide pathologists during the diagnostic process.</div></section><section id=\"abs-sec-4\"><h3>Conclusions</h3><div role=\"paragraph\">In this study, we establish the first effective clinical application of AI-based AD in histopathology and demonstrate high performance on a unique real-world collection of GI biopsies. The proposed novel AD can flag anomalous cases, facilitate case prioritization, and reduce missed diagnoses, providing critical support for pathologists. By design, it can be expected to detect any pathological alteration including rare primary or metastatic cancers in GI biopsies. To our knowledge, no other published AI tool is capable of zero-shot pan-cancer detection. AD may enhance the safety of AI models in histopathology, thereby driving AI adoption and automation in routine diagnostics and beyond.</div></section>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIcs2400661",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIcs2400661",
      "title": "AI for Oncology Drug Data Harmonization \u2014 Amazon versus OpenAI",
      "summary": "This case study gives an evaluation of the ability of potentially powerful computational tools available to the drug development community to harmonize real-world oncology data as the foundation for scalable drug development informatics pipelines.",
      "content_text": "## Abstract\n\nMedical-domain natural language processing (NLP) and general-domain large\nlanguage models (LLMs) are powerful computational tools available to the drug\ndevelopment community. These tools have the potential ability to harmonize\nreal-world oncology data, which could accelerate the standardization,\nintegration, and analysis of scalable drug development informatics pipelines,\nalbeit with differing associated costs. This potential use case was evaluated\nby extracting drugs indicated by the National Cancer Institute for single\nsolid tumor sites from openFDA. Requests to map diagnosis codes to drug label\nindications were submitted to the Amazon Comprehend Medical NLP service and\nthe OpenAI GPT-3.5 Turbo LLM using a general harmonization prompt (twice) and\na cancer-optimized prompt (once). The LLM approach performed similarly to the\nNLP approach (74.4% vs. 67.9%, P=0.480) and to itself (74.4% vs. 74.4%, P=1.0)\nwhen harmonizing the 78 oncology drugs. The cancer-optimized LLM prompts\nshowed greater harmonization accuracy than the NLP ones (89.7% vs. 67.9%,\nP=0.002), while LLM costs were approximately 3.7 times lower, showing that a\ngeneral-domain LLM was capable of being more accurate, adaptable, and cost-\neffective than conventional medical-domain NLP. (Funded by Pfizer, Inc.)\n\n",
      "date_published": "2024-10-18T00:00:00+00:00",
      "authors": [
        {
          "name": "J.G. Ronquillo and Others"
        }
      ],
      "tags": [
        "Case Study"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIcs2400661",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/bdec6b99-06c0-46aa-ad99-67ea6d07b532/aics2400661_f4.gif",
      "content_html": "<h2 property=\"name\">Abstract</h2><div role=\"paragraph\">Medical-domain natural language processing (NLP) and general-domain large language models (LLMs) are powerful computational tools available to the drug development community. These tools have the potential ability to harmonize real-world oncology data, which could accelerate the standardization, integration, and analysis of scalable drug development informatics pipelines, albeit with differing associated costs. This potential use case was evaluated by extracting drugs indicated by the National Cancer Institute for single solid tumor sites from openFDA. Requests to map diagnosis codes to drug label indications were submitted to the Amazon Comprehend Medical NLP service and the OpenAI GPT-3.5 Turbo LLM using a general harmonization prompt (twice) and a cancer-optimized prompt (once). The LLM approach performed similarly to the NLP approach (74.4% vs. 67.9%, P=0.480) and to itself (74.4% vs. 74.4%, P=1.0) when harmonizing the 78 oncology drugs. The cancer-optimized LLM prompts showed greater harmonization accuracy than the NLP ones (89.7% vs. 67.9%, P=0.002), while LLM costs were approximately 3.7 times lower, showing that a general-domain LLM was capable of being more accurate, adaptable, and cost-effective than conventional medical-domain NLP. (Funded by Pfizer, Inc.)</div>"
    },
    {
      "id": "https://ai.nejm.org/doi/full/10.1056/AIcs2400502",
      "url": "https://ai.nejm.org/doi/full/10.1056/AIcs2400502",
      "title": "Combining Multiple Large Language Models Improves Diagnostic Accuracy",
      "summary": "This study has tested the synthesis of high-accuracy differential diagnoses by aggregating responses from multiple heterogeneous large language models using methods for knowledge aggregation from the field of collective intelligence.",
      "content_text": "## Abstract\n\nAlthough large language models (LLMs), such as OpenAI GPT-4 or Google PaLM 2,\nare proposed as viable diagnostic support tools or even spoken of as\nreplacements for \u201ccurbside consults,\u201d past studies show that they may lack\nsufficient diagnostic accuracy for real-life applications. In an effort to\nimprove their accuracy and reduce the risk of misdiagnoses, we applied methods\nfrom the field of collective intelligence to produce synthetic differential\ndiagnoses that aggregate answers from individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, and Meta Llama 2). Using 200 clinical\nvignettes of real-life cases from the Human Diagnosis Project platform, we\nassessed and compared the accuracy of differential diagnoses from individual\nLLMs with those from aggregated LLM responses. We aggregated the LLM responses\ninto synthetic differential diagnoses using a simple frequency-based, 1/_r_\n-weighted method, in which more weight is given to diagnoses appearing near\nthe top of the LLM responses and appearing in the responses of multiple LLMs.\nWe evaluated all possible combinations of LLMs by calculating various TOP-_n_\naccuracy metrics: that is, how frequently the correct diagnosis matches any of\nthe first _n_ diagnoses. We found that aggregating responses from multiple\nLLMs leads to more accurate differential diagnoses (average TOP-5 accuracy for\nthree LLMs: 75.3%\u00b11.6 percentage points) compared with the differential\ndiagnoses produced by single LLMs (average TOP-5 accuracy for single LLMs:\n59.0%\u00b16.1 percentage points). We also found that aggregating smaller and less\ncapable models (TOP-5 accuracy for three smaller LLMs, not including GPT-4:\n70.0%) can rival the accuracy of the top-performing model (TOP-5 accuracy for\nGPT-4: 72.0%). The use of collective intelligence methods to synthesize\ndifferential diagnoses, combining the responses of different LLMs, achieves\nthree of the necessary steps toward advancing LLMs as a diagnostic support\ntool: demonstrating sufficiently high diagnostic accuracy, reducing the risk\nof misdiagnoses, and eliminating the dependence on a single commercial vendor.\n(Funded by the European Union\u2019s Horizon Europe research and innovation\nprogram.)\n\n",
      "date_published": "2024-10-17T00:00:00+00:00",
      "authors": [
        {
          "name": "G. Barabucci and Others"
        }
      ],
      "tags": [
        "Case Study"
      ],
      "attachments": [
        {
          "url": "https://ai.nejm.org/doi/pdf/10.1056/AIcs2400502",
          "mime_type": "application/pdf"
        }
      ],
      "image": "https://ai.nejm.org/cms/asset/d3c8c271-96c2-43ba-af08-c4a56731c61f/aics2400502_f1.gif",
      "content_html": "<h2 property=\"name\">Abstract</h2><div role=\"paragraph\">Although large language models (LLMs), such as OpenAI GPT-4 or Google PaLM 2, are proposed as viable diagnostic support tools or even spoken of as replacements for \u201ccurbside consults,\u201d past studies show that they may lack sufficient diagnostic accuracy for real-life applications. In an effort to improve their accuracy and reduce the risk of misdiagnoses, we applied methods from the field of collective intelligence to produce synthetic differential diagnoses that aggregate answers from individual commercial LLMs (OpenAI GPT-4, Google PaLM 2, Cohere Command, and Meta Llama 2). Using 200 clinical vignettes of real-life cases from the Human Diagnosis Project platform, we assessed and compared the accuracy of differential diagnoses from individual LLMs with those from aggregated LLM responses. We aggregated the LLM responses into synthetic differential diagnoses using a simple frequency-based, 1/<i>r</i>-weighted method, in which more weight is given to diagnoses appearing near the top of the LLM responses and appearing in the responses of multiple LLMs. We evaluated all possible combinations of LLMs by calculating various TOP-<i>n</i> accuracy metrics: that is, how frequently the correct diagnosis matches any of the first <i>n</i> diagnoses. We found that aggregating responses from multiple LLMs leads to more accurate differential diagnoses (average TOP-5 accuracy for three LLMs: 75.3%\u00b11.6 percentage points) compared with the differential diagnoses produced by single LLMs (average TOP-5 accuracy for single LLMs: 59.0%\u00b16.1 percentage points). We also found that aggregating smaller and less capable models (TOP-5 accuracy for three smaller LLMs, not including GPT-4: 70.0%) can rival the accuracy of the top-performing model (TOP-5 accuracy for GPT-4: 72.0%). The use of collective intelligence methods to synthesize differential diagnoses, combining the responses of different LLMs, achieves three of the necessary steps toward advancing LLMs as a diagnostic support tool: demonstrating sufficiently high diagnostic accuracy, reducing the risk of misdiagnoses, and eliminating the dependence on a single commercial vendor. (Funded by the European Union\u2019s Horizon Europe research and innovation program.)</div>"
    }
  ]
}
